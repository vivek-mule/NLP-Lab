{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 10\n",
        "\n",
        "Name: Vivek Mule\n",
        "Roll: 381072\n",
        "PRN: 22420145\n",
        "\n",
        "#### Develop a Machine Translation system to translate public information content between English and any Indian language."
      ],
      "metadata": {
        "id": "nWlrE5UeEvcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yceWB7MfEz6d",
        "outputId": "42211472-a40b-4587-90e3-df809fe1edf4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict, Counter"
      ],
      "metadata": {
        "id": "3OWcArdNFC_A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    return text.split()"
      ],
      "metadata": {
        "id": "6yp1tLFoFEGG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NGramModel:\n",
        "    def __init__(self, n=3):\n",
        "        self.n = n\n",
        "        self.ngram_counts = defaultdict(Counter)\n",
        "        self.context_counts = Counter()\n",
        "        self.vocab = set()\n",
        "\n",
        "    def train(self, tokens):\n",
        "        self.vocab = set(tokens)\n",
        "\n",
        "        for i in range(len(tokens)):\n",
        "            for k in range(1, self.n + 1):\n",
        "                if i - k + 1 < 0:\n",
        "                    continue\n",
        "\n",
        "                ngram = tuple(tokens[i-k+1:i+1])\n",
        "                context = tuple(tokens[i-k+1:i]) if k > 1 else ()\n",
        "\n",
        "                self.ngram_counts[context][ngram[-1]] += 1\n",
        "                self.context_counts[context] += 1\n",
        "\n",
        "    def get_probability(self, context, word):\n",
        "        vocab_size = len(self.vocab)\n",
        "        count = self.ngram_counts[context][word]\n",
        "        total = self.context_counts[context]\n",
        "        return (count + 1) / (total + vocab_size)\n",
        "\n",
        "    def predict_next(self, text, top_k=5):\n",
        "        tokens = preprocess_text(text)\n",
        "\n",
        "        # Backoff: trigram → bigram → unigram\n",
        "        for k in range(self.n-1, -1, -1):\n",
        "            context = tuple(tokens[-k:]) if k > 0 else ()\n",
        "\n",
        "            if context in self.ngram_counts:\n",
        "                candidates = {}\n",
        "\n",
        "                for word in self.vocab:\n",
        "                    prob = self.get_probability(context, word)\n",
        "                    candidates[word] = prob\n",
        "\n",
        "                sorted_words = sorted(\n",
        "                    candidates.items(),\n",
        "                    key=lambda x: x[1],\n",
        "                    reverse=True\n",
        "                )\n",
        "\n",
        "                return sorted_words[:top_k]\n",
        "\n",
        "        return []"
      ],
      "metadata": {
        "id": "eqJUK0PAFFMV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"\"\"\n",
        "Natural language processing (NLP) is technology that allows computers to interpret, manipulate, and comprehend human language. Organizations today have large volumes of voice and text data from various communication channels like emails, text messages, social media newsfeeds, video, audio, and more.\"\"\"\n",
        "\n",
        "tokens = preprocess_text(corpus)\n",
        "\n",
        "model = NGramModel(n=3)\n",
        "model.train(tokens)\n",
        "\n",
        "print(\"Model trained successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43rb0OedFGlw",
        "outputId": "2ea79b47-16a2-43d7-b485-98b044df6321"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"\\nEnter text (or 'exit'): \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    predictions = model.predict_next(user_input)\n",
        "\n",
        "    print(\"Suggestions:\")\n",
        "    for word, prob in predictions:\n",
        "        print(f\"{word}  (prob={round(prob,4)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA7ZCFMAFUEK",
        "outputId": "038ea475-9f59-48ea-8183-8694848ba8fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter text (or 'exit'): technology\n",
            "Suggestions:\n",
            "that  (prob=0.0526)\n",
            "natural  (prob=0.0263)\n",
            "large  (prob=0.0263)\n",
            "video  (prob=0.0263)\n",
            "social  (prob=0.0263)\n",
            "\n",
            "Enter text (or 'exit'): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fc1gWGF2FWfE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}