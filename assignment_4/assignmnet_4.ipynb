{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e03aacac",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "Name: Vivek Mule\n",
    "Roll: 381072\n",
    "PRN: 22420145\n",
    "\n",
    "Build a Named Entity Recognition (NER) system for extracting\n",
    "entities from real-world text such as news articles or social media\n",
    "data. And measure its accuracy, precision, recall, and F1 score.\n",
    "\n",
    "Named Entity Recognition (NER) identifies and classifies\n",
    "entities in text into predefined categories such as:\n",
    "PERSON,\n",
    "ORG (Organization),\n",
    "GPE (Location),\n",
    "DATE,\n",
    "EVENT,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3299de92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'C:\\Users\\vivek\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\vivek\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (transformers + metrics + CPU torch)\n",
    "%pip -q install transformers seqeval\n",
    "%pip -q install torch --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c01172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a969b5c6ac94c80b9af5d2955410bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9d730b9bcb4fe1b3b9818d3642266d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef34b2f3e524ff38bbb2c0937c62d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification LOAD REPORT from: dslim/bert-base-NER\n",
      "Key                      | Status     |  | \n",
      "-------------------------+------------+--+-\n",
      "bert.pooler.dense.bias   | UNEXPECTED |  | \n",
      "bert.pooler.dense.weight | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455b22da67a1449387bfc745b81519bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2dd061df1e04dbabfe2328a10929e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c98bd1d69f4ce8a5e51f669574a527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e40ac47127a455ebeb290d12ee0cb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: dslim/bert-base-NER\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import List, Dict, Tuple\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load pretrained NER pipeline (aggregated spans for cleaner entities)\n",
    "ner_tagger = pipeline(\n",
    "    task=\"token-classification\",\n",
    "    model=\"dslim/bert-base-NER\",\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "print(\"Loaded model:\", ner_tagger.model.name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9c97ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Span:\n",
    "    start: int\n",
    "    end: int\n",
    "    label: str\n",
    "\n",
    "\n",
    "def mentions_to_spans(text: str, mentions: List[Tuple[str, str]]) -> List[Span]:\n",
    "    \"\"\"Convert ordered mention strings to character spans using sequential search.\"\"\"\n",
    "    spans: List[Span] = []\n",
    "    cursor = 0\n",
    "    for mention, label in mentions:\n",
    "        start = text.index(mention, cursor)\n",
    "        end = start + len(mention)\n",
    "        spans.append(Span(start, end, label))\n",
    "        cursor = end\n",
    "    return spans\n",
    "\n",
    "\n",
    "raw_samples = [\n",
    "    (\n",
    "        \"Apple Inc. announced a new iPhone in Cupertino on September 12, 2023 during its annual event.\",\n",
    "        [(\"Apple Inc.\", \"ORG\"), (\"Cupertino\", \"GPE\"), (\"September 12, 2023\", \"DATE\")],\n",
    "    ),\n",
    "    (\n",
    "        \"Elon Musk met with NASA officials in Washington to discuss the Artemis program.\",\n",
    "        [(\"Elon Musk\", \"PERSON\"), (\"NASA\", \"ORG\"), (\"Washington\", \"GPE\"), (\"Artemis\", \"EVENT\")],\n",
    "    ),\n",
    "    (\n",
    "        \"The UN held an emergency session in New York after the earthquake in Turkey.\",\n",
    "        [(\"UN\", \"ORG\"), (\"New York\", \"GPE\"), (\"Turkey\", \"GPE\")],\n",
    "    ),\n",
    "    (\n",
    "        \"Manchester United defeated Chelsea 2-0 at Wembley on May 15, 2022.\",\n",
    "        [(\"Manchester United\", \"ORG\"), (\"Chelsea\", \"ORG\"), (\"Wembley\", \"GPE\"), (\"May 15, 2022\", \"DATE\")],\n",
    "    ),\n",
    "    (\n",
    "        \"Barack Obama spoke at the Climate Summit 2021 in Paris.\",\n",
    "        [(\"Barack Obama\", \"PERSON\"), (\"Climate Summit 2021\", \"EVENT\"), (\"Paris\", \"GPE\")],\n",
    "    ),\n",
    "    (\n",
    "        \"The World Health Organization declared COVID-19 a pandemic on March 11, 2020.\",\n",
    "        [(\"World Health Organization\", \"ORG\"), (\"COVID-19\", \"EVENT\"), (\"March 11, 2020\", \"DATE\")],\n",
    "    ),\n",
    "    (\n",
    "        \"Amazon opened a new data center in Mumbai to serve customers across India.\",\n",
    "        [(\"Amazon\", \"ORG\"), (\"Mumbai\", \"GPE\"), (\"India\", \"GPE\")],\n",
    "    ),\n",
    "    (\n",
    "        \"Lionel Messi signed a contract with Inter Miami CF in July 2023.\",\n",
    "        [(\"Lionel Messi\", \"PERSON\"), (\"Inter Miami CF\", \"ORG\"), (\"July 2023\", \"DATE\")],\n",
    "    ),\n",
    "]\n",
    "\n",
    "dataset = [\n",
    "    {\n",
    "        \"text\": text,\n",
    "        \"gold\": mentions_to_spans(text, mentions),\n",
    "    }\n",
    "    for text, mentions in raw_samples\n",
    "]\n",
    "\n",
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee846b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>entity_group</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>MISC</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>0.988667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cupertino</td>\n",
       "      <td>LOC</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>0.997524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word entity_group  start  end     score\n",
       "0  Apple Inc          ORG      0    9  0.999356\n",
       "1     iPhone         MISC     27   33  0.988667\n",
       "2  Cupertino          LOC     37   46  0.997524"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample_text = dataset[0][\"text\"]\n",
    "preds = ner_tagger(sample_text)\n",
    "pd.DataFrame(preds)[[\"word\", \"entity_group\", \"start\", \"end\", \"score\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "800b21c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tp': 7,\n",
       " 'fp': 17,\n",
       " 'fn': 19,\n",
       " 'precision': 0.2916666666666667,\n",
       " 'recall': 0.2692307692307692,\n",
       " 'f1': 0.27999999999999997,\n",
       " 'entity_accuracy': 0.16279069767441862}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(samples: List[Dict]) -> Dict[str, float]:\n",
    "    tp = fp = fn = 0\n",
    "    for sample in samples:\n",
    "        text = sample[\"text\"]\n",
    "        gold_spans = { (s.start, s.end, s.label) for s in sample[\"gold\"] }\n",
    "        pred_raw = ner_tagger(text)\n",
    "        pred_spans = { (p[\"start\"], p[\"end\"], p[\"entity_group\"]) for p in pred_raw }\n",
    "\n",
    "        tp += len(gold_spans & pred_spans)\n",
    "        fp += len(pred_spans - gold_spans)\n",
    "        fn += len(gold_spans - pred_spans)\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp else 0.0\n",
    "    recall = tp / (tp + fn) if tp + fn else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0.0\n",
    "    accuracy = tp / (tp + fp + fn) if tp + fp + fn else 0.0\n",
    "\n",
    "    return {\n",
    "        \"tp\": tp,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"entity_accuracy\": accuracy,\n",
    "    }\n",
    "\n",
    "\n",
    "metrics = evaluate(dataset)\n",
    "metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
